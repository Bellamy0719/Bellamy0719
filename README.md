# ðŸ‘‹ Hi, I'm Hongming Liu

**Data Engineer | Data Analyst | Data Scientist in Progress | Cloud & AI Enthusiast**

With 3 years of hands-on experience in data engineering and analytics, I build scalable cloud data pipelines and intelligent analytics systems that connect engineering precision with data insight.

---

## ðŸ§© Technical Focus

**Core Expertise**  
ETL Automation Â· PySpark Â· Airflow Â· Docker Â· SQL Â· Data Modeling Â· AWS Â· Databricks Â· Streaming (Kinesis)  

**Expanding Skills**  
dbt Â· MLflow Â· SageMaker Â· Feature Store Â· Data Governance (Delta Lake / Iceberg)  

**Analytical & Data Science Background**  
Experienced in classical modeling: Linear Regression, Logistic Regression, Decision Trees, and Time Series Analysis.  
Currently exploring Machine Learning and AI applications â€” including model deployment, feature pipelines, and Transformer-based architectures.

---

## ðŸš€ Project Highlights

### Airflow + Docker + PostgreSQL + Tableau
Automated batch ETL pipeline for stock data â€” covering ingestion, feature engineering, and dashboard visualization.  
**Focus:** Workflow orchestration, data validation, automation.

âž¡ï¸ [View Project](https://github.com/Bellamy0719/airflow-stock-pipeline)

---

### AWS + Databricks + PySpark Lakehouse
Designed a 3-tier S3 data lake (raw, processed, curated) using PySpark, Glue, Athena, and QuickSight.  
**Focus:** Scalable analytics, data lakehouse architecture, schema management.

âž¡ï¸ [View Project](https://github.com/Bellamy0719/aws-pyspark-data-lakehouse-pipeline)

---

### Kinesis + Databricks Streaming + S3
Real-time streaming pipeline with PySpark Structured Streaming.  
**Focus:** Windowing, watermarking, incremental writes, and near real-time aggregation.

âž¡ï¸ [View Project](https://github.com/yourusername/aws-kinesis-streaming-pipeline)

---

## ðŸ“ˆ Data Science & AI Direction

Building on my analytical foundation, I am transitioning toward **ML & AI systems engineering**:  
- Integrating ML models into production-ready pipelines (with MLflow / SageMaker)  
- Exploring **Transformer architectures, LLM-based pipelines**, and retrieval-augmented generation (RAG)  
- Bridging **data engineering, machine learning, and AI applications** end-to-end

---

## ðŸ§  Current Goals
- Develop a dbt-based transformation layer with modular, testable data models  
- Implement MLflow for tracking, deployment, and monitoring  
- Build an AI-ready data foundation for advanced analytics and intelligent automation

---

## ðŸ§© Tech Stack Overview

**Languages:** Python, SQL  
**Data Engineering:** PySpark, Airflow, Docker, dbt, AWS (S3, Glue, Athena, Redshift), Databricks  
**Streaming:** Kinesis (Kafka-based architecture)  
**Data Science:** pandas, scikit-learn, statsmodels  
**Visualization:** Tableau, QuickSight  
**Next Steps:** MLflow, SageMaker, Transformers, LangChain

---

> Building data systems that scale from pipelines to intelligence.
